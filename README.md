# Resume Analyzer API

API assÃ­ncrona para anÃ¡lise e ranking de currÃ­culos utilizando Python (FastAPI), Celery, RabbitMQ e LLMs (OpenRouter).

## ğŸš€ Funcionalidades

- **Upload de mÃºltiplos currÃ­culos (PDF)**: Processamento paralelo.
- **ExtraÃ§Ã£o de Texto**: Suporte robusto a diferentes formatos de PDF via `pdfminer.six`.
- **AnÃ¡lise com IA**: ExtraÃ§Ã£o estruturada de dados (Skills, ExperiÃªncia, Senioridade) e pontuaÃ§Ã£o de match com a vaga.
- **Ranking AutomÃ¡tico**: ClassificaÃ§Ã£o dos candidatos baseada em critÃ©rios objetivos.
- **RelatÃ³rio Consolidado**: GeraÃ§Ã£o de recomendaÃ§Ã£o final de contrataÃ§Ã£o.
- **Arquitetura EscalÃ¡vel**: SeparaÃ§Ã£o entre API e Workers AssÃ­ncronos.

## ğŸ› ï¸ Stack TecnolÃ³gica

- **Python 3.11**
- **FastAPI**: API REST
- **Celery**: Fila de tarefas distribuÃ­das
- **RabbitMQ**: Message Broker
- **Redis**: Backend de resultados e cache
- **OpenRouter (LLM)**: InteligÃªncia Artificial para anÃ¡lise
- **Docker & Docker Compose**: OrquestraÃ§Ã£o de containers

## ğŸ“¦ Como Executar

### PrÃ©-requisitos
- Docker e Docker Compose instalados.
- Uma chave de API da OpenRouter (jÃ¡ configurada no `.env` para teste).

### Passos

1. **Clone o repositÃ³rio** (se estiver em um):
   ```bash
   git clone <repo-url>
   cd Automatiz
   ```

2. **Verifique o arquivo `.env`**:
   Certifique-se de que o arquivo `.env` existe na raiz com sua chave `OPENROUTER_API_KEY`.

3. **Suba a aplicaÃ§Ã£o**:
   ```bash
   docker-compose up --build
   ```
   *Aguarde alguns instantes para que todos os serviÃ§os (RabbitMQ, Web, Worker) iniciem.*

4. **Acesse a DocumentaÃ§Ã£o (Swagger UI)**:
   Abra seu navegador em: [http://localhost:8000/docs](http://localhost:8000/docs)

## ğŸ§ª Como Testar

1. No Swagger UI, vÃ¡ para o endpoint `POST /api/v1/analyze`.
2. Clique em **Try it out**.
3. Em **files**, selecione mÃºltiplos arquivos PDF (ex: os currÃ­culos da pasta `Docs`).
4. Em **job_description**, cole a descriÃ§Ã£o da vaga desejada.
5. Execute. A API retornarÃ¡ um `task_id`.
6. Copie o `task_id` e use no endpoint `GET /api/v1/result/{task_id}` para acompanhar o status (`PROCESSING` -> `COMPLETED`) e ver o relatÃ³rio final.

## ğŸ“‚ Estrutura do Projeto

```
/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/            # Endpoints da API
â”‚   â”œâ”€â”€ core/           # ConfiguraÃ§Ãµes (Env, Celery)
â”‚   â”œâ”€â”€ models/         # Schemas Pydantic
â”‚   â”œâ”€â”€ services/       # LÃ³gica (PDF, LLM, Ranking)
â”‚   â””â”€â”€ tasks/          # Tarefas do Celery
â”œâ”€â”€ tests/              # Testes unitÃ¡rios
â”œâ”€â”€ docker-compose.yml  # OrquestraÃ§Ã£o
â”œâ”€â”€ Dockerfile          # Imagem Python
â””â”€â”€ requirements.txt    # DependÃªncias
```

## ğŸ“ DecisÃµes Arquiteturais

- **Processamento AssÃ­ncrono**: O upload de arquivos Ã© rÃ¡pido, delegando a anÃ¡lise pesada (PDF + LLM) para workers em background. Isso evita timeout na requisiÃ§Ã£o HTTP.
- **Chord do Celery**: Utilizamos o padrÃ£o `chord` para paralelizar a anÃ¡lise de N currÃ­culos e, somente apÃ³s o tÃ©rmino de todos, executar a tarefa de consolidaÃ§Ã£o/ranking.
- **File Handling**: Arquivos sÃ£o salvos temporariamente no disco (volume compartilhado) para evitar passar grandes binÃ¡rios pelo Message Broker, aumentando a performance.
  - *Nota Arquitetural*: Em um ambiente de produÃ§Ã£o distribuÃ­do, recomenda-se o uso de um **Object Storage** (AWS S3, MinIO) para o compartilhamento de arquivos entre API e Workers.
- **ResiliÃªncia**: Fallback na extraÃ§Ã£o de PDF e tratamento de erros na comunicaÃ§Ã£o com a LLM para garantir que um arquivo corrompido nÃ£o falhe todo o lote.
